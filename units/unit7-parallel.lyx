#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage[unicode=true]{hyperref}
\usepackage{/accounts/gen/vis/paciorek/latex/paciorek-asa,times,graphics}
\input{/accounts/gen/vis/paciorek/latex/paciorekMacros}
%\renewcommand{\baselinestretch}{1.5}
\hypersetup{unicode=true, pdfusetitle,bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=true,}
\end_preamble
\use_default_options false
\begin_modules
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing onehalf
\use_hyperref false
\papersize letterpaper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Unit 7: Parallel Processing 
\end_layout

\begin_layout Standard
\begin_inset Flex Chunk
status open

\begin_layout Plain Layout

\begin_inset Argument 1
status open

\begin_layout Plain Layout
chunk_setup, include=FALSE
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

library(knitr)
\end_layout

\begin_layout Plain Layout

library(parallel)
\end_layout

\begin_layout Plain Layout

read_chunk("unit7-parallel.R")
\end_layout

\end_inset


\end_layout

\begin_layout Standard
References: 
\end_layout

\begin_layout Itemize
Tutorial on basic parallel processing: 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/berkeley-scf/tutorial-parallel-basics"

\end_inset


\end_layout

\begin_layout Itemize
Tutorial on distributed parallel processing: 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/berkeley-scf/tutorial-parallel-distributed"

\end_inset

.
\end_layout

\begin_layout Standard
This unit will be fairly Linux-focused as most serious parallel computation
 is done on systems where some variant of Linux is running.
 The single-machine parallelization discussed here should work on Macs,
 but only some of the approaches are likely to work on Windows machines.
\end_layout

\begin_layout Section
Overview
\end_layout

\begin_layout Subsection
Computer architecture
\end_layout

\begin_layout Standard
Computers now come with multiple processors for doing computation.
 Basically, physical constraints have made it harder to keep increasing
 the speed of individual processors, so the chip industry is now putting
 multiple processing units in a given computer and trying/hoping to rely
 on implementing computations in a way that takes advantage of the multiple
 processors.
\end_layout

\begin_layout Standard
Everyday personal computers usually have more than one processor (more than
 one chip) and on a given processor, often have more than one core (multi-core).
 A multi-core processor has multiple processors on a single computer chip.
 On personal computers, all the processors and cores share the same memory.
\end_layout

\begin_layout Standard
Supercomputers and computer clusters generally have tens, hundreds, or thousands
 of 'nodes', linked by a fast local network.
 Each node is essentially a computer with its own processor(s) and memory.
 Memory is local to each node (distributed memory).
 One basic principle is that communication between a processor and its memory
 is much faster than communication between processors with different memory.
 An example of a modern supercomputer is the Edison supercomputer at Lawrence
 Berkeley National Lab, which has 5,586 nodes, each with two processors
 and each processor with 12 cores, giving 134,064 total processing cores.
 Each node has 64 GB of memory for a total of 357 TB of memory.
\end_layout

\begin_layout Standard
There is little practical distinction between multi-processor and multi-core
 situations.
 The main issue is whether processes share memory or not.
 In general, I won't distinguish between cores and processors.
 We'll just focus on the number of cores on given personal computer or a
 given node in a cluster.
\end_layout

\begin_layout Subsection
Some useful terminology:
\end_layout

\begin_layout Itemize
cores: We'll use this term to mean the different processing units available
 on a single node.
\end_layout

\begin_layout Itemize
nodes: We'll use this term to mean the different computers, each with their
 own distinct memory, that make up a cluster or supercomputer.
 
\end_layout

\begin_layout Itemize
processes: computational tasks executing on a machine; multiple processes
 may be executing at once.
 A given program may start up multiple processes at once.
 Ideally we have no more processes than cores on a node.
\end_layout

\begin_layout Itemize
threads: multiple paths of execution within a single process; the OS sees
 the threads as a single process, but one can think of them as 'lightweight'
 processes.
 Ideally when considering the processes and their threads, we would the
 same number of cores as we have processes and threads combined.
 
\end_layout

\begin_layout Itemize
forking: child processes are spawned that are identical to the parent, but
 with different process IDs and their own memory.
 
\end_layout

\begin_layout Itemize
sockets: some of R's parallel functionality involves creating new R processes
 (e.g., starting processes via 
\emph on
Rscript
\emph default
) and communicating with them via a communication technology called sockets.
\end_layout

\begin_layout Subsection
Distributed vs.
 shared memory
\end_layout

\begin_layout Standard
There are two basic flavors of parallel processing (leaving aside GPUs):
 distributed memory and shared memory.
 With shared memory, multiple processors (which I'll call cores for the
 rest of this document) share the same memory.
 With distributed memory, you have multiple nodes, each with their own memory.
 You can think of each node as a separate computer connected by a fast network.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
[see George's pdf for graphical representation, p.
 23]
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Shared memory
\end_layout

\begin_layout Standard
For shared memory parallelism, each core is accessing the same memory so
 there is no need to pass information (in the form of messages) between
 different machines.
 But in some programming contexts one needs to be careful that activity
 on different cores doesn't mistakenly overwrite places in memory that are
 used by other cores.
\end_layout

\begin_layout Standard
We'll cover two types of shared memory parallelism approaches in this unit:
 
\end_layout

\begin_layout Itemize
threaded linear algebra 
\end_layout

\begin_layout Itemize
multicore functionality 
\end_layout

\begin_layout Paragraph
Threading
\end_layout

\begin_layout Standard
Threads are multiple paths of execution within a single process.
 If you are monitoring CPU usage (such as with 
\emph on
top
\emph default
 in Linux or Mac) and watching a job that is executing threaded code, you'll
 see the process using more than 100% of CPU.
 When this occurs, the process is using multiple cores, although it appears
 as a single process rather than as multiple processes.
\end_layout

\begin_layout Standard
Note that this is a different notion than a processor that is hyperthreaded.
 With hyperthreading a single core appears as two cores to the operating
 system.
\end_layout

\begin_layout Subsubsection
Distributed memory
\end_layout

\begin_layout Standard
Parallel programming for distributed memory parallelism requires passing
 messages between the different nodes.
 The standard protocol for doing this is MPI, of which there are various
 versions, including 
\emph on
openMPI
\emph default
.
 
\end_layout

\begin_layout Standard
The R package 
\emph on
Rmpi
\emph default
 implements MPI in R.
 The 
\emph on
pbdR
\emph default
 packages for R also implement MPI as well as distributed linear algebra
 (linear algebra calculations across nodes).
 In addition, there are various ways to do simple parallelization of multiple
 computational tasks (across multiple nodes) that use MPI and other tools
 on the back-end without users needing to understand them.
 We won't cover distributed memory parallelization in this Unit, but we
 will touch on a flavor of it via Spark in Unit 8.
\end_layout

\begin_layout Subsection
Some other approaches to parallel processing
\end_layout

\begin_layout Subsubsection
GPUs
\end_layout

\begin_layout Standard
GPUs (Graphics Processing Units) are processing units originally designed
 for rendering graphics on a computer quickly.
 This is done by having a large number of simple processing units for massively
 parallel calculation.
 The idea of general purpose GPU (GPGPU) computing is to exploit this capability
 for general computation.
 In spring 2016, I gave a 
\begin_inset CommandInset href
LatexCommand href
name "workshop on using GPUs"
target "http://statistics.berkeley.edu/computing/gpu"

\end_inset

.
\end_layout

\begin_layout Standard
Most researchers don't program for a GPU directly but rather use software
 (often machine learning software such as Tensorflow or Caffe) that has
 been programmed to take advantage of a GPU if one is available.
\end_layout

\begin_layout Subsubsection
Spark and Hadoop
\end_layout

\begin_layout Standard
Spark and Hadoop are systems for implementing computations in a distributed
 memory environment, using the MapReduce approach.
 We'll see this in the next unit.
\end_layout

\begin_layout Subsubsection
Cloud computing
\end_layout

\begin_layout Standard
Amazon (Amazon Web Services' EC2 service), Google (Google Cloud Platform's
 Compute Engine service) and Microsoft (Azure) offer computing through the
 cloud.
 The basic idea is that they rent out their servers on a pay-as-you-go basis.
 You get access to a virtual machine that can run various versions of Linux
 or Microsoft Windows server and where you choose the number of processing
 cores you want.
 You configure the virtual machine with the applications, libraries, and
 data you need and then treat the virtual machine as if it were a physical
 machine that you log into as usual.
 You can also assemble multiple virtual machines into your own virtual cluster
 and use platforms such as Spark on the cloud provider's virtual machines.
 
\end_layout

\begin_layout Section
Threading, particularly for linear algebra
\end_layout

\begin_layout Subsection
What is the BLAS?
\end_layout

\begin_layout Standard
The BLAS is the library of basic linear algebra operations (written in Fortran
 or C).
 A fast BLAS can greatly speed up linear algebra relative to the default
 BLAS on a machine.
 Some fast BLAS libraries are 
\end_layout

\begin_layout Itemize
Intel's 
\emph on
MKL
\emph default
; may be available for educational use for free 
\end_layout

\begin_layout Itemize

\emph on
OpenBLAS
\emph default
; open source and free 
\end_layout

\begin_layout Itemize
AMD's 
\emph on
ACML
\emph default
; free 
\end_layout

\begin_layout Itemize

\emph on
vecLib
\emph default
 for Macs; provided with your Mac
\end_layout

\begin_layout Standard
In addition to being fast when used on a single core, all of these BLAS
 libraries are threaded - if your computer has multiple cores and there
 are free resources, your linear algebra will use multiple cores, provided
 your program is linked against the threaded BLAS installed on your machine
 and provided the environment variable OMP_NUM_THREADS is not set to one.
 (Macs make use of VECLIB_MAXIMUM_THREADS rather than OMP_NUM_THREADS.)
\end_layout

\begin_layout Standard
On the SCF, R is linked against OpenBLAS.
 
\end_layout

\begin_layout Subsection
Using threading 
\end_layout

\begin_layout Standard
Threading in R is limited to linear algebra, provided R is linked against
 a threaded BLAS.
\end_layout

\begin_layout Standard
Here's some code that illustrates the speed of using a threaded BLAS:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<R-linalg, eval=FALSE>>=
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Here the elapsed time indicates that using four threads gave us a three
 fold (3x) speedup in terms of real time, while the user time indicates
 that the threaded calculation took a bit more total processing time (combining
 time across all processors) because of the overhead of using multiple threads.
 
\end_layout

\begin_layout Standard
Note that the code also illustrates use of an R package (
\emph on
RhpcBLASctl
\emph default
) that can control the number of threads from within R.
\end_layout

\begin_layout Subsection
Setting the number of threads (cores used)
\end_layout

\begin_layout Standard
In general, threaded code will detect the number of cores available on a
 machine and make use of them.
 However, you can also explicitly control the number of threads available
 to a process.
 
\end_layout

\begin_layout Standard
For most threaded code (that based on the openMP protocol), the number of
 threads can be set by setting the OMP_NUM_THREADS environment variable
 (VECLIB_MAXIMUM_THREADS on a Mac).
 E.g., to set it for four threads in the bash shell:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<set-OMP, engine='bash', eval=FALSE>>=
\end_layout

\begin_layout Plain Layout

export OMP_NUM_THREADS=4
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Do this before starting your R or Python session or before running your
 compiled executable.
 
\end_layout

\begin_layout Standard
Alternatively, you can set OMP_NUM_THREADS as you invoke your job, e.g., here
 with R:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<set-OMP2, engine='bash', eval=FALSE>>=
\end_layout

\begin_layout Plain Layout

OMP_NUM_THREADS=4 R CMD BATCH --no-save job.R job.out
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Important warnings about use of threaded BLAS
\end_layout

\begin_layout Subsubsection
Speed and threaded BLAS
\end_layout

\begin_layout Standard
In many cases, using multiple threads for linear algebra operations will
 outperform using a single thread, but there is no guarantee that this will
 be the case, in particular for operations with small matrices and vectors.
 Testing with openBLAS suggests that sometimes a job may take more time
 when using multiple threads; this seems to be less likely with ACML.
 This presumably occurs because openBLAS is not doing a good job in detecting
 when the overhead of threading outweights the gains from distributing the
 computations.
 You can compare speeds by setting OMP_NUM_THREADS to different values.
 In cases where threaded linear algebra is slower than unthreaded, you would
 want to set OMP_NUM_THREADS to 1.
 
\end_layout

\begin_layout Standard
More generally, if you are using the parallel tools in Section 3 to simultaneous
ly carry out many independent calculations (tasks), it is likely to be more
 effective to use the fixed number of cores available on your machine so
 as to split up the tasks, one per core, without taking advantage of the
 threaded BLAS (i.e., restricting each process to a single thread).
 
\end_layout

\begin_layout Subsubsection
Conflicts between openBLAS and various R functionality
\end_layout

\begin_layout Standard
In the past, I've seen various issues arising when using threaded linear
 algebra.
 In some cases when the parallelization uses forking (we'll see when this
 is the case later in the unit), I have seen cases where R hangs and doesn't
 finish the linear algebra calculation.
\end_layout

\begin_layout Standard
I've also seen a conflict between threaded linear algebra and R profiling
 (recall the discussion of profiling in Unit 4).
\end_layout

\begin_layout Standard
Some solutions are to set OMP_NUM_THREADS to 1 to prevent the BLAS from
 doing threaded calculations or to use parallelization approaches that avoid
 forking.
 
\end_layout

\begin_layout Subsection
Using an optimized BLAS on your own machine(s)
\end_layout

\begin_layout Standard
To use an optimized BLAS with R, talk to your systems administrator, see
 
\begin_inset CommandInset href
LatexCommand href
name "Section A.3 of the R Installation and Administration Manual"
target "https://cran.r-project.org/manuals.html"

\end_inset

 or 
\begin_inset CommandInset href
LatexCommand href
name "see these instructions to use vecLib BLAS from Apple's Accelerate framework on your own Mac"
target "http://statistics.berkeley.edu/computing/blas"

\end_inset

.
\end_layout

\begin_layout Section
Basic parallelized loops/maps/apply
\end_layout

\begin_layout Standard
All of the functionality discussed here applies ONLY if the iterations/loops
 of your calculations can be done completely separately and do not depend
 on one another; i.e., you can do the computation as separate processes without
 communication between the processes.
 This scenario is called an 
\emph on
embarrassingly parallel
\emph default
 computation
\end_layout

\begin_layout Subsection
Embarrassingly parallel (EP) problems
\end_layout

\begin_layout Standard
An EP problem is one that can be solved by doing independent computations
 as separate processes without communication between the processes.
 You can get the answer by doing separate tasks and then collecting the
 results.
 Examples in statistics include
\end_layout

\begin_layout Enumerate
simulations with many independent replicates
\end_layout

\begin_layout Enumerate
bootstrapping
\end_layout

\begin_layout Enumerate
stratified analyses
\end_layout

\begin_layout Enumerate
random forests
\end_layout

\begin_layout Enumerate
cross-validation.
\end_layout

\begin_layout Standard
The standard setup is that we have the same code running on different datasets.
 (Note that different processes may need different random number streams,
 as we will discuss in the Simulation Unit.)
\end_layout

\begin_layout Standard
To do parallel processing in this context, you need to have control of multiple
 processes.
 Note that on a shared system with queueing/scheduling software set up,
 this will generally mean requesting access to a certain number of processors
 and then running your job in such a way that you use multiple processors.
 
\end_layout

\begin_layout Standard
In general, except for some modest overhead, an EP problem can ideally be
 solved with 
\begin_inset Formula $1/p$
\end_inset

 the amount of time for the non-parallel implementation, given 
\begin_inset Formula $p$
\end_inset

 cores.
 This gives us a speedup of 
\begin_inset Formula $p$
\end_inset

, which is called linear speedup (basically anytime the speedup is of the
 form 
\begin_inset Formula $kp$
\end_inset

 for some constant 
\begin_inset Formula $k$
\end_inset

).
\end_layout

\begin_layout Standard

\series bold
Question
\series default
: Suppose you have 
\begin_inset Formula $n$
\end_inset

 tasks to do where 
\begin_inset Formula $n\gg p$
\end_inset

.
 How should you divide up the 
\begin_inset Formula $n$
\end_inset

 tasks amongst the 
\begin_inset Formula $p$
\end_inset

 cores? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
overhead w/ many small; keep all processors working with many small with
 sequential dispatch; need at least as many tasks as cores available; less
 communication with many large tasks
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In the next sections, we'll see a few approaches in R for dealing with EP
 problems.
\end_layout

\begin_layout Subsection
Parallel for loops with foreach
\end_layout

\begin_layout Standard
A simple way to exploit parallelism in R is to use the 
\emph on
foreach
\emph default
 package to do a for loop in parallel.
\end_layout

\begin_layout Standard
The foreach package provides a 
\emph on
foreach
\emph default
 command that allows you to do this easily.
 foreach can use a variety of parallel ``back-ends''.
 For our purposes, the main one is use of the 
\emph on
parallel
\emph default
 package to use shared memory cores.
 When using 
\emph on
parallel
\emph default
 as the back-end, you should see multiple processes (as many as you registered;
 ideally each at 100%) when you monitor CPU usage.
 The multiple processes are created by forking or using sockets.
 (foreach can also use 
\emph on
Rmpi
\emph default
 or 
\emph on
SNOW
\emph default
 to access cores in a distributed memory setting; please see the tutorial
 on distributed parallel processing mentioned above.)
\end_layout

\begin_layout Standard
Here we'll parallelize leave-one-out cross-validation for a random forest
 model.
 An iteration involves holding out a data point, fitting the model with
 all the other data points, and then predicting the held-out point.
 First, here's the code for doing a cross-validation prediction and for
 generating some fake data.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<rf-example>>=
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Now here's how we use foreach to do the computation in parallel:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<foreach>>=
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
(Note that the printed statements from `cat` are not showing up in the creation
 of this document but should show if you run the code.)
\end_layout

\begin_layout Standard
Note that foreach also provides functionality for collecting and managing
 the results to avoid some of the bookkeeping you would need to do if writing
 your own standard for loop.
 The result of foreach will generally be a list, unless we request the results
 be combined in different way, as we do here using 
\family typewriter
.combine = c
\family default
.
\end_layout

\begin_layout Standard
You can debug by running serially using 
\family typewriter
%do%
\family default
 rather than 
\family typewriter
%dopar%
\family default
.
 
\end_layout

\begin_layout Subsection
Parallel apply functionality
\end_layout

\begin_layout Standard
The 
\emph on
parallel
\emph default
 package has the ability to parallelize the various apply functions (
\emph on
apply()
\emph default
, 
\emph on
lapply()
\emph default
, 
\emph on
sapply()
\emph default
, etc.).
 It's a bit hard to find the 
\begin_inset CommandInset href
LatexCommand href
name "vignette for the parallel package"
target "http://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf"

\end_inset

 because 
\emph on
parallel
\emph default
 is not listed as one of the contributed packages on CRAN (it gets installed
 with R by default).
\end_layout

\begin_layout Standard
We'll consider parallel 
\emph on
lapply()
\emph default
 and 
\emph on
sapply()
\emph default
.
 These rely on having started a cluster using 
\emph on
cluster()
\emph default
, which uses the PSOCK mechanism as in the SNOW package - starting new jobs
 via Rscript and communicating via a technology called sockets.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<parSapply>>=
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Here the miniscule user time is probably because the time spent in the worker
 processes is not counted at the level of the overall master process that
 dispatches the workers.
\end_layout

\begin_layout Standard
For help with these functions and additional related parallelization functions
 (including 
\emph on
parApply()
\emph default
), see the help on 
\emph on
clusterApply
\emph default
.
\end_layout

\begin_layout Standard

\emph on
mclapply()
\emph default
 is an alternative that uses forking to start up the worker processes.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<mclapply>>=
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that some R packages can directly interact with the parallelization
 packages to work with multiple cores.
 E.g., the 
\emph on
boot
\emph default
 package can make use of the parallel package directly.
 
\end_layout

\begin_layout Subsection
Limitations in Windows
\end_layout

\begin_layout Standard
Forking in R is not possible on Windows, so parallelization on Windows would
 generally need to use approaches based on sockets and not based on forking.
\end_layout

\begin_layout Subsection
Loading packages and accessing global variables within your parallel tasks
\end_layout

\begin_layout Standard
Whether you need to explicitly load packages and export global variables
 from the master process to the parallelized worker processes depends on
 the details of how you are doing the parallelization.
\end_layout

\begin_layout Standard
With foreach with the 
\emph on
doParallel
\emph default
 backend, parallel apply-style statements (starting the cluster via 
\emph on
makeForkCluster()
\emph default
, instead of the default 
\emph on
makeCluster()
\emph default
), and 
\emph on
mclapply()
\emph default
, packages and global variables in the main R process are automatically
 available to the worker tasks without any work on your part.
 This is because all of these approaches fork the original R process, thereby
 creating worker processes with the same state as the original R process.
 Interestingly, this means that global variables in the forked worker processes
 are just references to the objects in memory in the original R process.
 So the additional processes do not use additional memory for those objects
 (despite what is shown in 
\emph on
top
\emph default
) and there is no time involved in making copies.
 However, if you modify objects in the worker processes then copies are
 made, as we've seen to be generally the case with R.
 
\end_layout

\begin_layout Standard
In contrast, with parallel apply-style statements when starting the cluster
 using the default 
\emph on
makeCluster()
\emph default
 (which sets up a so-called 
\emph on
PSOCK
\emph default
 cluster, starting the R worker processes via Rscript), one needs to load
 packages within the code that is executed in parallel.
 In addition one needs to use 
\emph on
clusterExport()
\emph default
 to tell R which objects in the global environment should be available to
 the worker processes.
 This involves making as many copies of the objects as there are worker
 processes, so one can easily exceed the physical memory (RAM) on the machine
 if one has large objects, and the copying of large objects will take time.
 
\end_layout

\begin_layout Section
Parallelization strategies
\end_layout

\begin_layout Standard
Some of the considerations that apply when thinking about how effective
 a given parallelization approach will be include:
\end_layout

\begin_layout Itemize
the amount of memory that will be used by the various processes,
\end_layout

\begin_layout Itemize
the amount of communication that needs to happen -- how much data will need
 to be passed between processes,
\end_layout

\begin_layout Itemize
the latency of any communication - how much delay/lag is there in sending
 data between processes or starting up a worker process, and
\end_layout

\begin_layout Itemize
to what extent do processes have to wait for other processes to finish before
 they can do their next step.
\end_layout

\begin_layout Standard
The following are some basic principles/suggestions for how to parallelize
 your computation.
\end_layout

\begin_layout Itemize
Should I use one machine/node or many machines/nodes?
\end_layout

\begin_deeper
\begin_layout Itemize
If you can do your computation on the cores of a single node using shared
 memory, that will be faster than using the same number of cores (or even
 somewhat more cores) across multiple nodes.
 Similarly, jobs with a lot of data/high memory requirements that one might
 think of as requiring Spark or Hadoop may in some cases be much faster
 if you can find a single machine with a lot of memory.
 
\end_layout

\begin_layout Itemize
That said, if you would run out of memory on a single node, then you'll
 need to use distributed memory.
\end_layout

\end_deeper
\begin_layout Itemize
What level or dimension should I parallelize over?
\end_layout

\begin_deeper
\begin_layout Itemize
If you have nested loops, you generally only want to parallelize at one
 level of the code.
 That said, there may be cases in which it is helpful to do both.
 Keep in mind whether your linear algebra is being threaded.
 Often you will want to parallelize over a loop and not use threaded linear
 algebra.
 
\end_layout

\begin_layout Itemize
Often it makes sense to parallelize the outer loop when you have nested
 loops.
 
\end_layout

\begin_layout Itemize
You generally want to parallelize in such a way that your code is load-balanced
 and does not involve too much communication.
 
\end_layout

\end_deeper
\begin_layout Itemize
How do I balance communication overhead with keeping my cores busy?
\end_layout

\begin_deeper
\begin_layout Itemize
If you have very few tasks, particularly if the tasks take different amounts
 of time, often some processors will be idle and your code poorly load-balanced.
 
\end_layout

\begin_layout Itemize
If you have very many tasks and each one takes little time, the communication
 overhead of starting and stopping the tasks will reduce efficiency.
\end_layout

\end_deeper
\begin_layout Itemize
Should multiple tasks be pre-assigned to a process (i.e., a worker) (sometimes
 called 
\emph on
prescheduling
\emph default
) or should tasks be assigned dynamically as previous tasks finish? 
\end_layout

\begin_deeper
\begin_layout Itemize
Basically if you have many tasks that each take similar time, you want to
 preschedule the tasks to reduce communication.
 If you have few tasks or tasks with highly variable completion times, you
 don't want to preschedule, to improve load-balancing.
 
\end_layout

\begin_layout Itemize
For R in particular, some of R's parallel functions allow you to say whether
 the tasks should be prescheduled.
 E.g., the 
\emph on
mc.preschedule
\emph default
 argument in 
\emph on
mclapply()
\emph default
 and the 
\emph on
.scheduling
\emph default
 argument in 
\emph on
parLapply()
\emph default
.
\end_layout

\end_deeper
\end_body
\end_document
